# 机器学习

## 1 机器学习基本概念
机器学习模型分为
+ 有监督学习模型
+ 无监督学习模型

###  1.1 有监督学习模型
有监督学习模型主要分为**单模型**和**集成学习**两种：
+ **单模型**使用一个独立算法处理数据来学习和预测。其特点为简单易懂，训练和预测过程透明，计算开销小、训练时间短，且易于调试定位问题。不过，它易受数据噪声和异常值影响。
+ **集成学习**则结合多个模型提升预测性能，增强鲁棒性。其优势在于能综合各模型长处，性能通常优于单模型，对噪声和异常值耐受性更好。但它也存在不足，实现与调试复杂，需管理多个模型及组合方式，训练和预测消耗更多计算资源与时间。

#### 1.1.1 单模型
- **线性模型**：
    - **线性回归**：用于建立因变量和自变量之间的线性关系，通过最小化误差平方和来确定模型参数，常用于预测数值型结果 。
    - **逻辑回归**：虽名字有“回归”，实则用于分类问题，利用对数几率函数将线性回归结果转化为概率值，判断样本所属类别。 
    - **Lasso**：在回归分析中引入L1正则化，可对系数进行压缩，实现特征选择和防止过拟合 。
    - **Ridge**：即岭回归，引入L2正则化，在回归系数估计中加入惩罚项，使系数估计更稳定，降低方差。 
- **k近邻**：基于实例的学习方法，给定测试样本，通过计算与训练集中样本的距离（如欧氏距离），找出k个最近邻样本，根据这些样本的类别（分类问题）或数值（回归问题）来预测测试样本的结果 。 
- **决策树**：
    - **ID3**：以信息增益为准则选择划分属性构建决策树，每次选择使信息增益最大的属性进行分裂。
    - **C5.0**：在ID3基础上改进，使用信息增益比，还能处理连续属性和缺失值，可生成规则集。 
    - **CART**：分类回归树，既能用于分类（二叉树，基于基尼指数选择划分属性 ），也能用于回归（基于最小平方误差 ）。 
- **神经网络**：
    - **感知机**：最简单的神经网络模型，由输入层、输出层组成，通过权重调整学习输入和输出的映射关系，可解决线性可分问题。 
    - **神经网络**：通常指多层感知机，包含多个隐藏层，能学习复杂的非线性映射关系，通过反向传播算法更新权重。 
- **支持向量机**：
    - **线性可分**：在样本线性可分情况下，寻找能最大化样本间隔的超平面进行分类。 
    - **线性支持**：针对近似线性可分情况，引入松弛变量允许部分样本出错。 
    - **线性不可分**：通过核函数将样本映射到高维空间，使其线性可分，再寻找最优超平面。 

#### 1.1.2 集成学习
- **Boosting**：
    - **GBDT**：梯度提升决策树，基于梯度下降思想，每次迭代拟合残差的近似值（负梯度 ），不断构建新决策树来提升模型性能。 
    - **AdaBoost**：通过改变样本权重，让后续弱学习器更关注之前被误分类的样本，迭代训练多个弱学习器并加权组合成强学习器。 
    - **XGBoost**：对GBDT的优化，在目标函数中加入正则项控制模型复杂度，支持并行计算，训练效率高，广泛应用于数据挖掘竞赛等领域。 
    - **LightGBM**：采用直方图算法等优化策略，减少内存占用和计算量，支持更快的并行学习，在处理大规模数据时表现出色。 
    - **CatBoost**：能自动处理类别型特征，采用排序提升算法，减少梯度估计偏差，在准确性和鲁棒性方面有不错表现。 
- **Bagging**：
    - **随机森林**：基于Bagging集成学习方法，从原始训练集有放回抽样构建多个子集，每个子集训练一棵决策树，最终通过对多棵树的预测结果进行投票（分类）或平均（回归）得到最终结果，能有效降低方差，防止过拟合。 


### 1.2 无监督学习模型
**无监督学习模型中的两个主要类别：聚类和降维。**


#### 1.2.1 聚类
+ 聚类: 是一种无监督学习技术，用于将数据集中相似的数据点分组。
  + K-means: 一种基于质心的聚类算法，通过迭代优化质心位置以最小化每个点到其所在簇中心的距离。
  + 层次聚类: 创建层次关系的聚类方法，可分为自底向上的聚合层次聚类和自顶向下的分裂层次聚类。
  + 谱聚类: 利用图论、通过计算数据点之间的相似度矩阵以进行聚类的方法。

#### 1.2.2  降维
+ 降维: 是无监督学习中的另一种方法，用于减少数据集的特征维数，同时尽量保留数据的主要信息。
  + PCA (主成分分析): 通过线性变换将数据映射到新的坐标系中，新坐标系的轴（主成分）按数据方差大小排序，以保留最大方差信息。
  + SVD (奇异值分解): 一种矩阵因子分解技术，常用于数据降维和压缩。
  + LDA (线性判别分析): 尽管通常用作监督学习，其思路也被用作降维技术，通过最大化类间分隔和最小化类内分布。


### 1.3 什么是监督学习？什么是非监督学习？
所有的回归算法和分类算法都属于监督学习。并且明确的给给出初始值，在训练集中有特征和标签，并且通过训练获得一个模型，在面对只有特征而没有标签的数据时，能进行预测。

### 1.4 







































